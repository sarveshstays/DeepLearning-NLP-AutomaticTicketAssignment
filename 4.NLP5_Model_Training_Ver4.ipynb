{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Capstone_Interim_NLP5_Model_Training_Ver3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJyHrxL7ddNc",
        "colab_type": "text"
      },
      "source": [
        "### Modelling Approach - \n",
        "\n",
        "Part 1.\n",
        "Build a Model 1 which can classify the ticket as L1/L2 or L3 class.\n",
        "\n",
        "Part 2.\n",
        "Train 2 separate models for l1/l2 Class and l3 class, these models will be called on test set depending on the output of first model.\n",
        "\n",
        "For both models in step 1 and 2 dataset would be description text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9JsbvWJdI89",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "This file will help train the model based on all the EDA done in the file \" ???? \"\n",
        "\n",
        "The intent is to seperate out the modelling part from the EDA.\n",
        "\n",
        "At then end of the execution of this file, we will have mdoel states saved which will be used to predict the new incoming data in seperate python file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t50JRvhKJ0Zk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "291e64ff-8a2d-49f9-c553-557c5323d613"
      },
      "source": [
        "# import all necessary libraries\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import itertools\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "import string\n",
        "import math\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, roc_auc_score\n",
        "from sklearn.metrics import precision_score, recall_score, roc_curve, auc\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "from collections import OrderedDict\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Embedding,LSTM,Dense,SpatialDropout1D, Input,Flatten\n",
        "from keras.initializers import Constant\n",
        "from keras.utils import np_utils\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will switch to TensorFlow 2.x on the 27th of March, 2020.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now\n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltpo_jFsK90X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Set your project path \n",
        "project_path =  '/content/drive/My Drive/Colab Notebooks/DataSets'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GflekmCULAvY",
        "colab_type": "code",
        "outputId": "6ba979c6-0827-4fb2-a5aa-374259fa825a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-MOBJBTLFdf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set the google drive directory path to read and save all files there\n",
        "os.chdir(project_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ee4yvLIe2BI",
        "colab_type": "text"
      },
      "source": [
        "Taking groups which have ticket counts greater than 200 in one part and remaining in the other part. This was done in EDA\n",
        "\n",
        "Based on tickets we will name one group as L12 and other as L3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpG98rEkJ7OJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#L12 = ['GRP_0', 'GRP_8', 'GRP_90']\n",
        "#L3 = ['GRP_97','GRP_98','GRP_99']\n",
        "L12 = ['GRP_0', 'GRP_8', 'GRP_24', 'GRP_12', 'GRP_9', 'GRP_2', 'GRP_19', 'GRP_3']\n",
        "L3  = ['GRP_10', 'GRP_13', 'GRP_14','GRP_5','GRP_25','GRP_98','GRP_99']\n",
        "#L3  = ['GRP_10', 'GRP_13', 'GRP_14','GRP_5', 'GRP_6','GRP_25','GRP_98','GRP_99']\n",
        "# L3 = [ 'GRP_1', 'GRP_4', 'GRP_5', 'GRP_6', 'GRP_7', 'GRP_10', 'GRP_11',  'GRP_13', 'GRP_14', 'GRP_15', 'GRP_16', 'GRP_17', 'GRP_18', \n",
        "      #  'GRP_20', 'GRP_21', 'GRP_22', 'GRP_23',  'GRP_25', 'GRP_26', 'GRP_27', 'GRP_28', 'GRP_29', 'GRP_30', 'GRP_31',\n",
        "      #  'GRP_33', 'GRP_34', 'GRP_35', 'GRP_36', 'GRP_37', 'GRP_38', 'GRP_39', 'GRP_40', 'GRP_41', 'GRP_42', 'GRP_43', 'GRP_44',\n",
        "      #  'GRP_45', 'GRP_46', 'GRP_47', 'GRP_48', 'GRP_49', 'GRP_50',  'GRP_51', 'GRP_52', 'GRP_53', 'GRP_54', 'GRP_55', 'GRP_56',\n",
        "      #  'GRP_57', 'GRP_58', 'GRP_59', 'GRP_60', 'GRP_61', 'GRP_32',  'GRP_62', 'GRP_63', 'GRP_64', 'GRP_65',\n",
        "      #  'GRP_66', 'GRP_67', 'GRP_68', 'GRP_69', 'GRP_70', 'GRP_71', 'GRP_72', 'GRP_73']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoF5BEF5fCLU",
        "colab_type": "text"
      },
      "source": [
        "Defining the variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4tHhBgZfE7h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocabulary = dict()\n",
        "inverse_vocabulary = ['<unk>']\n",
        "embedding_dim = 300\n",
        "embeddings = 1 * np.random.randn(30000, embedding_dim)\n",
        "   \n",
        "colsToTrainOn =['LemmaString']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uotk6G27hOFh",
        "colab_type": "text"
      },
      "source": [
        "Encode the two groups L12/L3 in 0 and 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUP2CQteKFCf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def SetGrp(text):\n",
        "  ''' this will set the L12 to 0\n",
        "  and L3 to 1'''\n",
        "  \n",
        "  if text in L12:\n",
        "      return 0\n",
        "  if text in L3:\n",
        "      return 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "is5_LvA0KKZI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def readFile():    \n",
        "  ''' This function will read the file that is saved after the EDA completion\n",
        "  Will drop NA values which contitute only 9 rows in total\n",
        "  will apply the normal cleaning methods of removing dupliates, removing some regex list, and punctuations from the text columns\n",
        "  Will convert text to word list\n",
        "  Combine to columns into one\n",
        "  Set Level Groups to 0 or 1 '''\n",
        "\n",
        "  #df = pd.read_excel('EDA_Processed_Cleaned_TicketData.xlsx')\n",
        "  df = pd.read_excel('EDA_Processed_Cleaned_TicketData_OverSample.xlsx')\n",
        "\n",
        "  dfSubset = df[['LemmaString','NewAssignmentGroup']]\n",
        "\n",
        "  dfSubset['Level1Grp'] = 0\n",
        "  dfSubset['Level1Grp'] = dfSubset['NewAssignmentGroup'].apply(lambda x : SetGrp(x))\n",
        " \n",
        "  # df['LemmaString'] = df['LemmaString'].apply(lambda x : text_to_word_list(x))\n",
        "  # df['LemmaStringRetained'] = df['LemmaString']\n",
        "  \n",
        "  return dfSubset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPfvR6ZcKOuH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def PrepDataForPrediction(df,vocabulary,inverse_vocabulary):\n",
        "  ''' Will create the vocabulary and inverse_vocabulary list to be used in embedding \n",
        "  and later to be referred when we will call the same in our predict section '''\n",
        "  \n",
        "  for dataset in [df]:\n",
        "    for index, row in dataset.iterrows():\n",
        "\n",
        "      # Iterate through the text of description column of the row\n",
        "      for question in colsToTrainOn:\n",
        "        q2n = []  \n",
        "        for word in row[question]:\n",
        "          if word not in vocabulary:\n",
        "              vocabulary[word] = len(inverse_vocabulary)\n",
        "              q2n.append(len(inverse_vocabulary))\n",
        "              inverse_vocabulary.append(word)\n",
        "          else:\n",
        "              q2n.append(vocabulary[word])\n",
        "            # Replace description as word to description as number representation\n",
        "          dataset.at[index, question]= q2n\n",
        "  return df, vocabulary,inverse_vocabulary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-x_M-xEKjU3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def PrepDataForModel_FirstLevelGrouping(df,max_seq_length):\n",
        "  \"\"\"First prepare the X and Y by getting the combined description column in the X and Level 1 grouping in Y\n",
        "  Once this is done then split the data using the train test split and test size randomly given\n",
        "  After that pad the X_train and X_validation sequences\n",
        "  Return X_train, Y_train, X_validation,Y_validation\"\"\"\n",
        "  \n",
        "  X = df[colsToTrainOn[0]]\n",
        "  Y = np_utils.to_categorical(df['Level1Grp'])\n",
        "    \n",
        "  X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size=math.floor(len(X)*0.2))\n",
        "  X_train = pad_sequences(X_train, maxlen=maxlen,truncating='post',padding='post',value=0)\n",
        "  X_validation = pad_sequences(X_validation, maxlen=maxlen,truncating='post',padding='post',value=0)\n",
        "  return X_train, Y_train, X_validation,Y_validation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HM85is6e9UpH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def PrepDataForModel_SecondLevelGrouping(df,max_seq_length):\n",
        "  \"\"\"This function will first create the two data frames one with groups defined in L12 and other in L3. \n",
        "  The objective of this is to find the actual Assignment Group the model will predict finally\n",
        "  Will encode the Assignment Groups falling in both the dataframes based on filteration\n",
        "  Will create two train test split sets. One that will have for L12 groups and the other for the L3 groups\n",
        "  Will pad the sequences of all such train and validation data\n",
        "  And finally will return below values for model training\n",
        "  X_train_Zero, Y_train_Zero, X_validation_Zero,Y_validation_Zero,X_train_One,X_validation_One,Y_train_One,Y_validation_One,partDfZero,partDfOne\"\"\"\n",
        "\n",
        "  partDfZero = df.loc[df['Level1Grp'] == 0]\n",
        "  partDfOne = df.loc[df['Level1Grp'] == 1]\n",
        "\n",
        "  le1 = LabelEncoder()\n",
        "  le2 = LabelEncoder()\n",
        "  \n",
        "  # class_weightsZero = class_weight.compute_class_weight('balanced', np.unique(df['AssignmentGroup']), df['AssignmentGroup'])\n",
        "  # class_weightsOne = class_weight.compute_class_weight('balanced', np.unique(df['AssignmentGroup']), df['AssignmentGroup'])\n",
        "\n",
        "  partDfZero['NewAssignmentGroup'] = le1.fit_transform(partDfZero['NewAssignmentGroup'])\n",
        "  partDfOne['NewAssignmentGroup'] = le2.fit_transform(partDfOne['NewAssignmentGroup'])\n",
        "\n",
        "  X_Zero = partDfZero[colsToTrainOn[0]]\n",
        "  Y_Zero = np_utils.to_categorical(partDfZero['NewAssignmentGroup'])\n",
        "\n",
        "  X_One = partDfOne[colsToTrainOn[0]]\n",
        "  Y_One = np_utils.to_categorical(partDfOne['NewAssignmentGroup'])\n",
        "\n",
        "  X_train_Zero, X_validation_Zero, Y_train_Zero, Y_validation_Zero = train_test_split(X_Zero, Y_Zero, test_size=math.floor(len(X_Zero)*0.2))\n",
        "  X_train_One, X_validation_One, Y_train_One, Y_validation_One = train_test_split(X_One, Y_One, test_size=math.floor(len(X_One)*0.2))\n",
        "\n",
        "  X_train_Zero = pad_sequences(X_train_Zero, maxlen=maxlen,truncating='post',padding='post',value=0)\n",
        "  X_validation_Zero = pad_sequences(X_validation_Zero, maxlen=maxlen,truncating='post',padding='post',value=0)\n",
        "\n",
        "  X_train_One = pad_sequences(X_train_One, maxlen=maxlen,truncating='post',padding='post',value=0)\n",
        "  X_validation_One = pad_sequences(X_validation_One, maxlen=maxlen,truncating='post',padding='post',value=0)\n",
        "\n",
        "  # return X_train_Zero, Y_train_Zero, X_validation_Zero,Y_validation_Zero,X_train_One,X_validation_One,Y_train_One,Y_validation_One,partDfZero,partDfOne, class_weightsZero, class_weightsOne\n",
        "  return X_train_Zero, Y_train_Zero, X_validation_Zero,Y_validation_Zero,X_train_One,X_validation_One,Y_train_One,Y_validation_One,partDfZero,partDfOne"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8cFDNmsjhYq",
        "colab_type": "text"
      },
      "source": [
        "Create the embedding matrix. Here Word2Vec is used because of its being trained over the Wikipedia and has better coverage of all words and beautifully trained on wiki"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOpVl9qhKvfX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def BuildEmbeddingMatrix(word2vec):\n",
        "  ''' prepare the ebedding vector matrix using the word2vec '''\n",
        "  \n",
        "  count = 0    \n",
        "  for word, index in vocabulary.items():\n",
        "    if word in word2vec.vocab:\n",
        "        count+=1\n",
        "        embeddings[index] = word2vec.word_vec(word)\n",
        "    else:\n",
        "        embeddings[index] = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8f3QhNoddXbQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGl0T9YDjviL",
        "colab_type": "text"
      },
      "source": [
        "This method will help to dump the emebddings, the vocabulary and inverse_vocabulary created for further use in predict model in different python file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1mx3qQGPnza",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def PickleCustomObjects(embeddings,vocabulary,inverse_vocabulary):\n",
        "  ''' this function will help dump the embeddings, vocabulary and inverse_vocabulary\n",
        "  which will be referred in predict model python file when we will predict the new incoming data '''\n",
        "\n",
        "  with open('embeddings.pickle', 'wb') as f:\n",
        "      pickle.dump(embeddings, f, pickle.HIGHEST_PROTOCOL)\n",
        "      \n",
        "  with open('vocabulary.pickle', 'wb') as f:\n",
        "      pickle.dump(vocabulary, f, pickle.HIGHEST_PROTOCOL)\n",
        "      \n",
        "  with open('inverse_vocabulary.pickle', 'wb') as f:\n",
        "      pickle.dump(inverse_vocabulary, f, pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKOo4nPR89Ii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_scores(y_test,y_pred):\n",
        "    print(\"Accuracy score: \\n\", accuracy_score(y_test,y_pred))\n",
        "    print('Test-set confusion matrix:\\n', confusion_matrix(y_test,y_pred))\n",
        "    cm = confusion_matrix(y_test,y_pred)\n",
        "    sns.heatmap(cm, annot=True, fmt='g')\n",
        "    print(\"Classification report:\" \"\\n\", classification_report(y_test,y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpjdxjeT89i7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n",
        "  lb = preprocessing.LabelBinarizer()\n",
        "  lb.fit(y_test)\n",
        "  y_test = lb.transform(y_test)\n",
        "  y_pred = lb.transform(y_pred)\n",
        "  return roc_auc_score(y_test, y_pred, average=average)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPNhP47B31ua",
        "colab_type": "code",
        "outputId": "1d0ba196-98e6-4626-986f-2eeebdda269b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#read files with some processing\n",
        "df = readFile()\n",
        "\n",
        "print(df['Level1Grp'].value_counts())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    11425\n",
            "1     5546\n",
            "Name: Level1Grp, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxLk_Uh_4Drb",
        "colab_type": "code",
        "outputId": "e064221a-e666-49e3-f5f4-ccf211ea2507",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "#display top 5 records \n",
        "df.head(5)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LemmaString</th>\n",
              "      <th>NewAssignmentGroup</th>\n",
              "      <th>Level1Grp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>login issue verify user detail employee manage...</td>\n",
              "      <td>GRP_0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>outlook team meeting skype not appear calendar...</td>\n",
              "      <td>GRP_0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ca not log vpn can not</td>\n",
              "      <td>GRP_0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>unable access hr tool</td>\n",
              "      <td>GRP_0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>unable log engineer tool skype</td>\n",
              "      <td>GRP_0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         LemmaString  ... Level1Grp\n",
              "0  login issue verify user detail employee manage...  ...         0\n",
              "1  outlook team meeting skype not appear calendar...  ...         0\n",
              "2                             ca not log vpn can not  ...         0\n",
              "3                              unable access hr tool  ...         0\n",
              "4                     unable log engineer tool skype  ...         0\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBOpqEkFY88G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9KGRSWtY9nz",
        "colab_type": "text"
      },
      "source": [
        "### LSTM Start Here ->"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dighb5VDK1Q_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "maxlen = min(df['LemmaString'].map(lambda x:len(x)).max(), 150)\n",
        "df, vocabulary,inverse_vocabulary = PrepDataForPrediction(df,vocabulary,inverse_vocabulary)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfWov9Xlrm1b",
        "colab_type": "code",
        "outputId": "984daac1-7d89-4fb2-c75b-33b61a3a5047",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "df.head(10)\n",
        "#vocabulary"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LemmaString</th>\n",
              "      <th>NewAssignmentGroup</th>\n",
              "      <th>Level1Grp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[1, 2, 3, 4, 5, 6, 4, 7, 7, 8, 9, 6, 10, 9, 11...</td>\n",
              "      <td>GRP_0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[2, 8, 15, 1, 2, 2, 21, 6, 15, 9, 16, 17, 6, 1...</td>\n",
              "      <td>GRP_0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[19, 16, 6, 5, 2, 15, 6, 1, 2, 3, 6, 10, 18, 5...</td>\n",
              "      <td>GRP_0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[8, 5, 16, 23, 1, 9, 6, 16, 19, 19, 9, 7, 7, 6...</td>\n",
              "      <td>GRP_0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[8, 5, 16, 23, 1, 9, 6, 1, 2, 3, 6, 9, 5, 3, 4...</td>\n",
              "      <td>GRP_0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[9, 10, 9, 5, 15, 6, 19, 11, 4, 15, 4, 19, 16,...</td>\n",
              "      <td>GRP_99</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[5, 2, 6, 9, 17, 18, 1, 2, 13, 17, 9, 5, 15, 6...</td>\n",
              "      <td>GRP_0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[8, 5, 16, 23, 1, 9, 6, 14, 4, 7, 16, 23, 1, 9...</td>\n",
              "      <td>GRP_0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[8, 18, 14, 16, 15, 9, 6, 4, 5, 18, 1, 16, 5, 15]</td>\n",
              "      <td>GRP_0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[9, 5, 3, 4, 5, 9, 9, 11, 6, 15, 2, 2, 1, 6, 5...</td>\n",
              "      <td>GRP_0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         LemmaString  ... Level1Grp\n",
              "0  [1, 2, 3, 4, 5, 6, 4, 7, 7, 8, 9, 6, 10, 9, 11...  ...         0\n",
              "1  [2, 8, 15, 1, 2, 2, 21, 6, 15, 9, 16, 17, 6, 1...  ...         0\n",
              "2  [19, 16, 6, 5, 2, 15, 6, 1, 2, 3, 6, 10, 18, 5...  ...         0\n",
              "3  [8, 5, 16, 23, 1, 9, 6, 16, 19, 19, 9, 7, 7, 6...  ...         0\n",
              "4  [8, 5, 16, 23, 1, 9, 6, 1, 2, 3, 6, 9, 5, 3, 4...  ...         0\n",
              "5  [9, 10, 9, 5, 15, 6, 19, 11, 4, 15, 4, 19, 16,...  ...         1\n",
              "6  [5, 2, 6, 9, 17, 18, 1, 2, 13, 17, 9, 5, 15, 6...  ...         0\n",
              "7  [8, 5, 16, 23, 1, 9, 6, 14, 4, 7, 16, 23, 1, 9...  ...         0\n",
              "8  [8, 18, 14, 16, 15, 9, 6, 4, 5, 18, 1, 16, 5, 15]  ...         0\n",
              "9  [9, 5, 3, 4, 5, 9, 9, 11, 6, 15, 2, 2, 1, 6, 5...  ...         0\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IeCG9gFK4EH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('word2vec.pickle', 'rb') as f:\n",
        "    word2vec = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jP8YDYKynkP9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BuildEmbeddingMatrix(word2vec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyAyPBAhP3v7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, Y_train, X_validation,Y_validation = PrepDataForModel_FirstLevelGrouping(df, maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byvidQBWZvpo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a52e0002-f4e4-439d-afd7-b0153026fcf3"
      },
      "source": [
        "print(\"X_train:      \", X_train.shape,      \" Y_train:      \", Y_train.shape)\n",
        "print(\"X_validation: \", X_validation.shape, \" Y_validation: \", Y_validation.shape)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train:       (13577, 150)  Y_train:       (13577, 2)\n",
            "X_validation:  (3394, 150)  Y_validation:  (3394, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URskFrfvvZSJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Dropout\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
        "from keras.models import Model\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cf73vAqnLWxt",
        "colab_type": "code",
        "outputId": "f9af6c40-76c0-43c9-f54b-ab3b00c5f19d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        }
      },
      "source": [
        "model_FirstLevelGrouping=Sequential()\n",
        "\n",
        "embedding=Embedding(len(embeddings),300,weights=[embeddings], input_length=maxlen,trainable=False)\n",
        "\n",
        "model_FirstLevelGrouping.add(embedding)\n",
        "\n",
        "#model_FirstLevelGrouping.add(LSTM(maxlen, recurrent_dropout=0.2))\n",
        "\n",
        "model_FirstLevelGrouping.add(Bidirectional(LSTM(maxlen, return_sequences=True, recurrent_dropout=0.25)))\n",
        "model_FirstLevelGrouping.add(Bidirectional(LSTM(maxlen, return_sequences=False)))\n",
        "\n",
        "#model_FirstLevelGrouping.add(Dropout(0.2))\n",
        "#model_FirstLevelGrouping.add(Dense(50, activation='relu'))\n",
        "#model_FirstLevelGrouping.add(Dropout(0.2))\n",
        "#model_FirstLevelGrouping.add(Dense(20, activation='relu'))\n",
        "#model_FirstLevelGrouping.add(Dropout(0.2))\n",
        "\n",
        " #we have two groups to target either L12(0) or L3(1)\n",
        "model_FirstLevelGrouping.add(Dense(2, activation='sigmoid'))\n",
        "model_FirstLevelGrouping.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "model_FirstLevelGrouping.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 150, 300)          9000000   \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 150, 300)          541200    \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 300)               541200    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 602       \n",
            "=================================================================\n",
            "Total params: 10,083,002\n",
            "Trainable params: 1,083,002\n",
            "Non-trainable params: 9,000,000\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SK3N5rXOG5nv",
        "colab_type": "code",
        "outputId": "4d20c9a9-1bc6-4dc3-8ef6-80a80fcc8fbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5)\n",
        "Y_train.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13577, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Zji1XY9Qc8I",
        "colab_type": "code",
        "outputId": "4d4cb1a8-c199-4ec2-e1c5-dc254777a13e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history=model_FirstLevelGrouping.fit(X_train,Y_train,batch_size=1000,epochs=50, class_weight = 'auto',\n",
        "                                     validation_data=(X_validation,Y_validation),\n",
        "                                     callbacks=[early],\n",
        "                                     verbose=1)\n",
        "\n",
        "scores = model_FirstLevelGrouping.evaluate(X_validation, Y_validation, verbose=1)\n",
        "y = model_FirstLevelGrouping.predict(X_train)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 13577 samples, validate on 3394 samples\n",
            "Epoch 1/50\n",
            "13577/13577 [==============================] - 21s 2ms/step - loss: 0.6181 - acc: 0.6748 - val_loss: 0.5883 - val_acc: 0.6811\n",
            "Epoch 2/50\n",
            "13577/13577 [==============================] - 17s 1ms/step - loss: 0.5684 - acc: 0.6947 - val_loss: 0.5678 - val_acc: 0.6890\n",
            "Epoch 3/50\n",
            "13577/13577 [==============================] - 17s 1ms/step - loss: 0.5493 - acc: 0.7111 - val_loss: 0.5443 - val_acc: 0.7298\n",
            "Epoch 4/50\n",
            "13577/13577 [==============================] - 17s 1ms/step - loss: 0.5300 - acc: 0.7261 - val_loss: 0.5182 - val_acc: 0.7416\n",
            "Epoch 5/50\n",
            "13577/13577 [==============================] - 17s 1ms/step - loss: 0.5084 - acc: 0.7398 - val_loss: 0.4997 - val_acc: 0.7550\n",
            "Epoch 6/50\n",
            "13577/13577 [==============================] - 17s 1ms/step - loss: 0.4904 - acc: 0.7552 - val_loss: 0.4823 - val_acc: 0.7537\n",
            "Epoch 7/50\n",
            "13577/13577 [==============================] - 17s 1ms/step - loss: 0.4739 - acc: 0.7674 - val_loss: 0.4703 - val_acc: 0.7703\n",
            "Epoch 8/50\n",
            "13577/13577 [==============================] - 17s 1ms/step - loss: 0.4625 - acc: 0.7781 - val_loss: 0.4473 - val_acc: 0.7824\n",
            "Epoch 9/50\n",
            "13577/13577 [==============================] - 17s 1ms/step - loss: 0.4403 - acc: 0.7908 - val_loss: 0.4291 - val_acc: 0.7980\n",
            "Epoch 10/50\n",
            "13577/13577 [==============================] - 17s 1ms/step - loss: 0.4150 - acc: 0.8066 - val_loss: 0.3953 - val_acc: 0.8266\n",
            "Epoch 11/50\n",
            "13577/13577 [==============================] - 17s 1ms/step - loss: 0.3874 - acc: 0.8245 - val_loss: 0.3707 - val_acc: 0.8413\n",
            "Epoch 12/50\n",
            "13577/13577 [==============================] - 17s 1ms/step - loss: 0.3628 - acc: 0.8380 - val_loss: 0.3461 - val_acc: 0.8561\n",
            "Epoch 13/50\n",
            "13577/13577 [==============================] - 17s 1ms/step - loss: 0.3294 - acc: 0.8612 - val_loss: 0.3208 - val_acc: 0.8726\n",
            "Epoch 14/50\n",
            "13577/13577 [==============================] - 17s 1ms/step - loss: 0.3039 - acc: 0.8773 - val_loss: 0.3032 - val_acc: 0.8883\n",
            "Epoch 15/50\n",
            "13577/13577 [==============================] - 17s 1ms/step - loss: 0.2684 - acc: 0.8964 - val_loss: 0.2933 - val_acc: 0.8953\n",
            "Epoch 16/50\n",
            "13577/13577 [==============================] - 17s 1ms/step - loss: 0.2437 - acc: 0.9103 - val_loss: 0.2643 - val_acc: 0.9059\n",
            "Epoch 17/50\n",
            "13577/13577 [==============================] - 16s 1ms/step - loss: 0.2192 - acc: 0.9205 - val_loss: 0.2507 - val_acc: 0.9128\n",
            "Epoch 18/50\n",
            "13577/13577 [==============================] - 16s 1ms/step - loss: 0.2005 - acc: 0.9304 - val_loss: 0.2527 - val_acc: 0.9132\n",
            "Epoch 19/50\n",
            "13577/13577 [==============================] - 16s 1ms/step - loss: 0.1825 - acc: 0.9354 - val_loss: 0.2448 - val_acc: 0.9199\n",
            "Epoch 20/50\n",
            "13577/13577 [==============================] - 17s 1ms/step - loss: 0.1654 - acc: 0.9419 - val_loss: 0.2516 - val_acc: 0.9203\n",
            "Epoch 21/50\n",
            "13577/13577 [==============================] - 16s 1ms/step - loss: 0.1552 - acc: 0.9456 - val_loss: 0.2335 - val_acc: 0.9241\n",
            "Epoch 22/50\n",
            "13577/13577 [==============================] - 16s 1ms/step - loss: 0.1374 - acc: 0.9514 - val_loss: 0.2377 - val_acc: 0.9302\n",
            "Epoch 23/50\n",
            "13577/13577 [==============================] - 16s 1ms/step - loss: 0.1240 - acc: 0.9575 - val_loss: 0.2421 - val_acc: 0.9274\n",
            "Epoch 24/50\n",
            "13577/13577 [==============================] - 17s 1ms/step - loss: 0.1122 - acc: 0.9624 - val_loss: 0.2507 - val_acc: 0.9238\n",
            "Epoch 25/50\n",
            "13577/13577 [==============================] - 17s 1ms/step - loss: 0.1056 - acc: 0.9626 - val_loss: 0.2489 - val_acc: 0.9308\n",
            "Epoch 26/50\n",
            "13577/13577 [==============================] - 17s 1ms/step - loss: 0.0928 - acc: 0.9679 - val_loss: 0.2529 - val_acc: 0.9321\n",
            "3394/3394 [==============================] - 44s 13ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWTWItmCQiZg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictedClass = np.argmax(y,axis=1).tolist() \n",
        "actualClass = np.argmax(Y_train,axis=1).tolist()\n",
        "   \n",
        "tempDf = pd.DataFrame()\n",
        "tempDf['ActualValue'] = pd.Series(actualClass)\n",
        "tempDf['PredictedClass'] = pd.Series(predictedClass)\n",
        "\n",
        "model_FirstLevelGrouping.save(\"model_FirstLevelGrouping.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mo4yU8NxyYAI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "outputId": "0b04aecf-6e0a-45b9-d0f2-a552587d4a51"
      },
      "source": [
        "print_scores(tempDf['ActualValue'], tempDf['PredictedClass'])\n",
        "print(\"ROC_AUC_Score: \", multiclass_roc_auc_score(tempDf['ActualValue'],tempDf['PredictedClass']))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score: \n",
            " 0.977756499963173\n",
            "Test-set confusion matrix:\n",
            " [[9111   46]\n",
            " [ 256 4164]]\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98      9157\n",
            "           1       0.99      0.94      0.97      4420\n",
            "\n",
            "    accuracy                           0.98     13577\n",
            "   macro avg       0.98      0.97      0.97     13577\n",
            "weighted avg       0.98      0.98      0.98     13577\n",
            "\n",
            "ROC_AUC_Score:  0.9685289843291758\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWYAAAD4CAYAAADfPUyRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzJKUGQOzJGXm/wGDqbnl7Bc/QAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGfn9tvKRK3x",
        "colab_type": "code",
        "outputId": "c434fc57-ad63-43ed-da94-7a3ad370eb19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(L12))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7U_LLHwXlmd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get the train test data for the actual assignment groups\n",
        "\n",
        "X_train_Zero, Y_train_Zero, X_validation_Zero,Y_validation_Zero,X_train_One,X_validation_One,Y_train_One,Y_validation_One,partDfZero,partDfOne = PrepDataForModel_SecondLevelGrouping(df, maxlen)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqXmsCkbLs4w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SECOND MODEL BEGINS HERE FOR GROUP 1 - All assignment groups that falls under L12 defined above\n",
        "\n",
        "model_L12_AssignmentGroups = Sequential()\n",
        "embedding=Embedding(len(embeddings),300,weights=[embeddings], input_length=maxlen,trainable=False)\n",
        "\n",
        "model_L12_AssignmentGroups.add(embedding)\n",
        "model_L12_AssignmentGroups.add(LSTM(maxlen))\n",
        "model_L12_AssignmentGroups.add(Dense(100, activation='relu'))\n",
        "model_L12_AssignmentGroups.add(Dropout(0.25) )\n",
        "model_L12_AssignmentGroups.add(Dense(80, activation='relu'))\n",
        "model_L12_AssignmentGroups.add(Dropout(0.25) )\n",
        "model_L12_AssignmentGroups.add(Dense(40, activation='relu'))\n",
        "model_L12_AssignmentGroups.add(Dropout(0.25) )\n",
        "model_L12_AssignmentGroups.add(Dense(20, activation='relu'))\n",
        "model_L12_AssignmentGroups.add(Dropout(0.25) )\n",
        "model_L12_AssignmentGroups.add(Dense(10, activation='relu'))\n",
        "model_L12_AssignmentGroups.add(Dropout(0.25) )\n",
        "\n",
        "model_L12_AssignmentGroups.add(Dense(len(L12), activation='softmax'))\n",
        "#model_L12_AssignmentGroups.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model_L12_AssignmentGroups.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4maFEwBS8As",
        "colab_type": "code",
        "outputId": "645c2643-113b-48b0-e3e6-bd171f762d18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history=model_L12_AssignmentGroups.fit(X_train_Zero,Y_train_Zero,batch_size=50,epochs=80, class_weight = 'auto',\n",
        "                                                   validation_data=(X_validation_Zero,Y_validation_Zero),\n",
        "                                                   callbacks=[early], \n",
        "                                                   verbose=1)\n",
        "\n",
        "scores = model_L12_AssignmentGroups.evaluate(X_validation_Zero, Y_validation_Zero, verbose=1)\n",
        "model_L12_AssignmentGroups.save(\"model_L12_AssignmentGroups.h5\")"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 9140 samples, validate on 2285 samples\n",
            "Epoch 1/80\n",
            "9140/9140 [==============================] - 58s 6ms/step - loss: 2.0184 - acc: 0.2678 - val_loss: 1.9931 - val_acc: 0.2972\n",
            "Epoch 2/80\n",
            "9140/9140 [==============================] - 52s 6ms/step - loss: 1.9852 - acc: 0.2975 - val_loss: 1.9669 - val_acc: 0.2985\n",
            "Epoch 3/80\n",
            "9140/9140 [==============================] - 52s 6ms/step - loss: 1.9682 - acc: 0.3010 - val_loss: 1.9589 - val_acc: 0.2967\n",
            "Epoch 4/80\n",
            "9140/9140 [==============================] - 51s 6ms/step - loss: 1.9563 - acc: 0.3042 - val_loss: 1.9491 - val_acc: 0.2980\n",
            "Epoch 5/80\n",
            "9140/9140 [==============================] - 52s 6ms/step - loss: 1.9000 - acc: 0.3156 - val_loss: 1.7699 - val_acc: 0.3479\n",
            "Epoch 6/80\n",
            "9140/9140 [==============================] - 52s 6ms/step - loss: 1.7916 - acc: 0.3470 - val_loss: 1.7128 - val_acc: 0.3536\n",
            "Epoch 7/80\n",
            "9140/9140 [==============================] - 52s 6ms/step - loss: 1.7251 - acc: 0.3626 - val_loss: 1.6864 - val_acc: 0.3567\n",
            "Epoch 8/80\n",
            "9140/9140 [==============================] - 52s 6ms/step - loss: 1.6848 - acc: 0.3691 - val_loss: 1.6513 - val_acc: 0.3694\n",
            "Epoch 9/80\n",
            "9140/9140 [==============================] - 52s 6ms/step - loss: 1.6671 - acc: 0.3778 - val_loss: 1.6267 - val_acc: 0.3829\n",
            "Epoch 10/80\n",
            "9140/9140 [==============================] - 52s 6ms/step - loss: 1.6155 - acc: 0.3828 - val_loss: 1.5899 - val_acc: 0.3751\n",
            "Epoch 11/80\n",
            "9140/9140 [==============================] - 52s 6ms/step - loss: 1.5772 - acc: 0.3887 - val_loss: 1.5444 - val_acc: 0.3742\n",
            "Epoch 12/80\n",
            "9140/9140 [==============================] - 52s 6ms/step - loss: 1.5294 - acc: 0.3947 - val_loss: 1.5137 - val_acc: 0.3772\n",
            "Epoch 13/80\n",
            "9140/9140 [==============================] - 53s 6ms/step - loss: 1.4875 - acc: 0.4001 - val_loss: 1.4606 - val_acc: 0.3947\n",
            "Epoch 14/80\n",
            "9140/9140 [==============================] - 53s 6ms/step - loss: 1.4443 - acc: 0.4080 - val_loss: 1.4174 - val_acc: 0.4031\n",
            "Epoch 15/80\n",
            "9140/9140 [==============================] - 52s 6ms/step - loss: 1.3881 - acc: 0.4173 - val_loss: 1.3868 - val_acc: 0.3991\n",
            "Epoch 16/80\n",
            "9140/9140 [==============================] - 52s 6ms/step - loss: 1.3306 - acc: 0.4307 - val_loss: 1.3013 - val_acc: 0.4538\n",
            "Epoch 17/80\n",
            "9140/9140 [==============================] - 52s 6ms/step - loss: 1.2787 - acc: 0.4704 - val_loss: 1.2875 - val_acc: 0.4853\n",
            "Epoch 18/80\n",
            "9140/9140 [==============================] - 52s 6ms/step - loss: 1.2284 - acc: 0.5068 - val_loss: 1.2096 - val_acc: 0.5090\n",
            "Epoch 19/80\n",
            "9140/9140 [==============================] - 52s 6ms/step - loss: 1.1821 - acc: 0.5293 - val_loss: 1.2570 - val_acc: 0.5164\n",
            "Epoch 20/80\n",
            "9140/9140 [==============================] - 52s 6ms/step - loss: 1.1380 - acc: 0.5572 - val_loss: 1.1473 - val_acc: 0.5532\n",
            "Epoch 21/80\n",
            "9140/9140 [==============================] - 53s 6ms/step - loss: 1.0661 - acc: 0.5778 - val_loss: 1.0668 - val_acc: 0.5860\n",
            "Epoch 22/80\n",
            "9140/9140 [==============================] - 52s 6ms/step - loss: 1.0245 - acc: 0.6034 - val_loss: 1.0037 - val_acc: 0.6105\n",
            "Epoch 23/80\n",
            "9140/9140 [==============================] - 52s 6ms/step - loss: 0.9643 - acc: 0.6303 - val_loss: 1.0018 - val_acc: 0.6136\n",
            "Epoch 24/80\n",
            "9140/9140 [==============================] - 53s 6ms/step - loss: 0.9544 - acc: 0.6299 - val_loss: 1.0303 - val_acc: 0.6171\n",
            "Epoch 25/80\n",
            "9140/9140 [==============================] - 52s 6ms/step - loss: 0.9045 - acc: 0.6586 - val_loss: 0.9097 - val_acc: 0.7020\n",
            "Epoch 26/80\n",
            "9140/9140 [==============================] - 52s 6ms/step - loss: 0.8460 - acc: 0.6892 - val_loss: 0.8515 - val_acc: 0.7221\n",
            "Epoch 27/80\n",
            "9140/9140 [==============================] - 52s 6ms/step - loss: 0.8266 - acc: 0.7003 - val_loss: 0.8619 - val_acc: 0.7059\n",
            "Epoch 28/80\n",
            "9140/9140 [==============================] - 52s 6ms/step - loss: 0.7768 - acc: 0.7216 - val_loss: 0.7710 - val_acc: 0.7729\n",
            "Epoch 29/80\n",
            "9140/9140 [==============================] - 52s 6ms/step - loss: 0.7338 - acc: 0.7484 - val_loss: 0.7847 - val_acc: 0.7615\n",
            "Epoch 30/80\n",
            "9140/9140 [==============================] - 52s 6ms/step - loss: 0.7025 - acc: 0.7623 - val_loss: 0.7470 - val_acc: 0.7799\n",
            "Epoch 31/80\n",
            "9140/9140 [==============================] - 52s 6ms/step - loss: 0.6686 - acc: 0.7739 - val_loss: 0.7426 - val_acc: 0.7698\n",
            "Epoch 32/80\n",
            "9140/9140 [==============================] - 52s 6ms/step - loss: 0.6528 - acc: 0.7787 - val_loss: 0.7021 - val_acc: 0.8031\n",
            "Epoch 33/80\n",
            "9140/9140 [==============================] - 51s 6ms/step - loss: 0.6409 - acc: 0.7947 - val_loss: 0.6993 - val_acc: 0.7961\n",
            "Epoch 34/80\n",
            "9140/9140 [==============================] - 51s 6ms/step - loss: 0.5901 - acc: 0.8068 - val_loss: 0.6833 - val_acc: 0.8162\n",
            "Epoch 35/80\n",
            "9140/9140 [==============================] - 51s 6ms/step - loss: 0.6418 - acc: 0.7894 - val_loss: 0.8840 - val_acc: 0.6691\n",
            "Epoch 36/80\n",
            "9140/9140 [==============================] - 52s 6ms/step - loss: 0.7349 - acc: 0.7384 - val_loss: 0.7263 - val_acc: 0.7641\n",
            "Epoch 37/80\n",
            "9140/9140 [==============================] - 51s 6ms/step - loss: 0.6154 - acc: 0.8005 - val_loss: 0.6629 - val_acc: 0.7891\n",
            "Epoch 38/80\n",
            "9140/9140 [==============================] - 52s 6ms/step - loss: 0.6177 - acc: 0.8004 - val_loss: 0.5981 - val_acc: 0.8403\n",
            "Epoch 39/80\n",
            "9140/9140 [==============================] - 51s 6ms/step - loss: 0.5661 - acc: 0.8200 - val_loss: 0.6410 - val_acc: 0.7934\n",
            "Epoch 40/80\n",
            "9140/9140 [==============================] - 52s 6ms/step - loss: 0.5211 - acc: 0.8358 - val_loss: 0.5511 - val_acc: 0.8503\n",
            "Epoch 41/80\n",
            "9140/9140 [==============================] - 52s 6ms/step - loss: 0.4919 - acc: 0.8463 - val_loss: 0.5919 - val_acc: 0.8429\n",
            "Epoch 42/80\n",
            "9140/9140 [==============================] - 52s 6ms/step - loss: 0.5285 - acc: 0.8350 - val_loss: 0.6150 - val_acc: 0.8105\n",
            "Epoch 43/80\n",
            "9140/9140 [==============================] - 52s 6ms/step - loss: 0.5567 - acc: 0.8177 - val_loss: 0.6185 - val_acc: 0.8048\n",
            "Epoch 44/80\n",
            "9140/9140 [==============================] - 52s 6ms/step - loss: 0.5317 - acc: 0.8300 - val_loss: 0.5396 - val_acc: 0.8595\n",
            "Epoch 45/80\n",
            "9140/9140 [==============================] - 51s 6ms/step - loss: 0.4630 - acc: 0.8563 - val_loss: 0.5589 - val_acc: 0.8451\n",
            "Epoch 46/80\n",
            "9140/9140 [==============================] - 51s 6ms/step - loss: 0.4427 - acc: 0.8646 - val_loss: 0.4975 - val_acc: 0.8779\n",
            "Epoch 47/80\n",
            "9140/9140 [==============================] - 52s 6ms/step - loss: 0.4681 - acc: 0.8521 - val_loss: 0.5900 - val_acc: 0.8381\n",
            "Epoch 48/80\n",
            "9140/9140 [==============================] - 52s 6ms/step - loss: 0.4866 - acc: 0.8516 - val_loss: 0.5050 - val_acc: 0.8617\n",
            "Epoch 49/80\n",
            "9140/9140 [==============================] - 51s 6ms/step - loss: 0.4212 - acc: 0.8790 - val_loss: 0.5198 - val_acc: 0.8503\n",
            "Epoch 50/80\n",
            "9140/9140 [==============================] - 52s 6ms/step - loss: 0.4218 - acc: 0.8742 - val_loss: 0.6073 - val_acc: 0.8171\n",
            "Epoch 51/80\n",
            "9140/9140 [==============================] - 52s 6ms/step - loss: 0.4602 - acc: 0.8540 - val_loss: 0.5352 - val_acc: 0.8516\n",
            "2285/2285 [==============================] - 7s 3ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfDuy3lwS7z3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = model_L12_AssignmentGroups.predict(X_train_Zero)\n",
        "predictedClass = np.argmax(y,axis=1).tolist()\n",
        "actualClass = np.argmax(Y_train_Zero,axis=1).tolist()\n",
        "    \n",
        "tempDf_L12_AssignmentGroups = pd.DataFrame()\n",
        "tempDf_L12_AssignmentGroups['ActualValue'] = pd.Series(actualClass)\n",
        "tempDf_L12_AssignmentGroups['PredictedClass'] = pd.Series(predictedClass)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcjKqsI4TFXd",
        "colab_type": "code",
        "outputId": "bf027f01-062c-4c0c-c13a-f33134402c7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(L3))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wf3TCA3pMOYw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SECOND MODEL BEGINS HERE FOR GROUP 2  - All assignment groups that falls under L3 defined above\n",
        "\n",
        "model_L3_AssignmentGroups = Sequential()\n",
        "embedding = Embedding(len(embeddings),300,weights=[embeddings], input_length=maxlen, trainable=False)\n",
        "\n",
        "model_L3_AssignmentGroups.add(embedding)\n",
        "model_L3_AssignmentGroups.add(LSTM(maxlen))\n",
        "model_L3_AssignmentGroups.add(Dense(100, activation='relu'))\n",
        "model_L3_AssignmentGroups.add(Dense(90, activation='relu'))\n",
        "model_L3_AssignmentGroups.add(Dense(70, activation='relu'))\n",
        "# model_L3_AssignmentGroups.add(Dropout(0.25) )\n",
        "\n",
        "#L3 subgroups\n",
        "model_L3_AssignmentGroups.add(Dense(len(L3), activation='softmax'))\n",
        "#model_L3_AssignmentGroups.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model_L3_AssignmentGroups.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ajb5vjl6TpOn",
        "colab_type": "code",
        "outputId": "68fbc087-6217-46ea-9493-9baaa3704302",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        }
      },
      "source": [
        "history=model_L3_AssignmentGroups.fit(X_train_One,Y_train_One, batch_size=10,epochs=50, class_weight = 'auto',\n",
        "                                      validation_data=(X_validation_One,Y_validation_One),\n",
        "                                      callbacks=[early], \n",
        "                                      verbose=1)\n",
        "\n",
        "scores = model_L3_AssignmentGroups.evaluate(X_validation_One, Y_validation_One, verbose=1)\n",
        "\n",
        "model_L3_AssignmentGroups.save(\"model_L3_AssignmentGroups.h5\")"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 4437 samples, validate on 1109 samples\n",
            "Epoch 1/50\n",
            "4437/4437 [==============================] - 140s 32ms/step - loss: 1.9351 - acc: 0.1783 - val_loss: 1.9234 - val_acc: 0.1794\n",
            "Epoch 2/50\n",
            "4437/4437 [==============================] - 122s 28ms/step - loss: 1.9106 - acc: 0.1830 - val_loss: 1.8797 - val_acc: 0.2191\n",
            "Epoch 3/50\n",
            "4437/4437 [==============================] - 122s 28ms/step - loss: 1.8323 - acc: 0.2270 - val_loss: 1.7920 - val_acc: 0.2480\n",
            "Epoch 4/50\n",
            "4437/4437 [==============================] - 123s 28ms/step - loss: 1.6208 - acc: 0.3164 - val_loss: 1.4803 - val_acc: 0.3697\n",
            "Epoch 5/50\n",
            "4437/4437 [==============================] - 123s 28ms/step - loss: 1.3806 - acc: 0.4411 - val_loss: 1.3160 - val_acc: 0.4716\n",
            "Epoch 6/50\n",
            "4437/4437 [==============================] - 124s 28ms/step - loss: 1.2107 - acc: 0.5152 - val_loss: 1.1905 - val_acc: 0.5203\n",
            "Epoch 7/50\n",
            "4437/4437 [==============================] - 124s 28ms/step - loss: 0.9281 - acc: 0.6441 - val_loss: 0.9225 - val_acc: 0.6456\n",
            "Epoch 8/50\n",
            "4437/4437 [==============================] - 124s 28ms/step - loss: 0.6648 - acc: 0.7532 - val_loss: 0.6958 - val_acc: 0.7547\n",
            "Epoch 9/50\n",
            "4437/4437 [==============================] - 125s 28ms/step - loss: 0.4967 - acc: 0.8161 - val_loss: 0.7976 - val_acc: 0.7178\n",
            "Epoch 10/50\n",
            "4437/4437 [==============================] - 124s 28ms/step - loss: 0.4733 - acc: 0.8220 - val_loss: 0.6410 - val_acc: 0.7773\n",
            "Epoch 11/50\n",
            "4437/4437 [==============================] - 126s 28ms/step - loss: 0.3392 - acc: 0.8664 - val_loss: 0.4891 - val_acc: 0.8088\n",
            "Epoch 12/50\n",
            "4437/4437 [==============================] - 126s 28ms/step - loss: 0.2799 - acc: 0.8796 - val_loss: 0.5357 - val_acc: 0.8088\n",
            "Epoch 13/50\n",
            "4437/4437 [==============================] - 126s 28ms/step - loss: 0.2834 - acc: 0.8855 - val_loss: 0.5474 - val_acc: 0.8251\n",
            "Epoch 14/50\n",
            "4437/4437 [==============================] - 126s 28ms/step - loss: 0.2707 - acc: 0.8884 - val_loss: 0.5714 - val_acc: 0.8016\n",
            "Epoch 15/50\n",
            "4437/4437 [==============================] - 124s 28ms/step - loss: 0.2478 - acc: 0.9008 - val_loss: 0.4795 - val_acc: 0.8287\n",
            "Epoch 16/50\n",
            "4437/4437 [==============================] - 124s 28ms/step - loss: 0.2024 - acc: 0.9121 - val_loss: 0.5794 - val_acc: 0.8251\n",
            "Epoch 17/50\n",
            "4437/4437 [==============================] - 123s 28ms/step - loss: 0.2022 - acc: 0.9180 - val_loss: 0.4628 - val_acc: 0.8503\n",
            "Epoch 18/50\n",
            "4437/4437 [==============================] - 123s 28ms/step - loss: 0.1987 - acc: 0.9249 - val_loss: 0.5580 - val_acc: 0.8404\n",
            "Epoch 19/50\n",
            "4437/4437 [==============================] - 124s 28ms/step - loss: 0.1586 - acc: 0.9371 - val_loss: 0.5365 - val_acc: 0.8485\n",
            "Epoch 20/50\n",
            "4437/4437 [==============================] - 123s 28ms/step - loss: 0.2126 - acc: 0.9182 - val_loss: 0.4556 - val_acc: 0.8413\n",
            "Epoch 21/50\n",
            "4437/4437 [==============================] - 124s 28ms/step - loss: 0.1747 - acc: 0.9355 - val_loss: 0.4821 - val_acc: 0.8485\n",
            "Epoch 22/50\n",
            "4437/4437 [==============================] - 123s 28ms/step - loss: 0.1309 - acc: 0.9488 - val_loss: 0.5183 - val_acc: 0.8458\n",
            "Epoch 23/50\n",
            "4437/4437 [==============================] - 122s 28ms/step - loss: 0.1877 - acc: 0.9310 - val_loss: 0.5464 - val_acc: 0.8386\n",
            "Epoch 24/50\n",
            "4437/4437 [==============================] - 123s 28ms/step - loss: 0.1680 - acc: 0.9362 - val_loss: 0.5588 - val_acc: 0.8305\n",
            "Epoch 25/50\n",
            "4437/4437 [==============================] - 122s 28ms/step - loss: 0.1149 - acc: 0.9583 - val_loss: 0.5249 - val_acc: 0.8557\n",
            "1109/1109 [==============================] - 3s 3ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXkFrR-mTpA-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = model_L3_AssignmentGroups.predict(X_train_One)\n",
        "predictedClass = np.argmax(y,axis=1).tolist()\n",
        "actualClass = np.argmax(Y_train_One,axis=1).tolist()\n",
        "    \n",
        "tempDf_L3_AssignmentGroups = pd.DataFrame()\n",
        "tempDf_L3_AssignmentGroups['ActualValue'] = pd.Series(actualClass)\n",
        "tempDf_L3_AssignmentGroups['PredictedClass'] = pd.Series(predictedClass)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMjPZXAhT5nZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PickleCustomObjects(embeddings,vocabulary,inverse_vocabulary)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFYxk03xWH9_",
        "colab_type": "text"
      },
      "source": [
        "### Section to print the Accuracy, Classification Report and Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jH3_mXwKg7iC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n",
        "  lb = preprocessing.LabelBinarizer()\n",
        "  lb.fit(y_test)\n",
        "  y_test = lb.transform(y_test)\n",
        "  y_pred = lb.transform(y_pred)\n",
        "  return roc_auc_score(y_test, y_pred, average=average)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4t8QOgY_UHi",
        "colab_type": "text"
      },
      "source": [
        "Showing Confusion Matrix for the Model trained over first level grouping of L12 and L3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWMS8JX0PAzv",
        "colab_type": "code",
        "outputId": "5a5659dd-fefe-464b-f44d-654f472f8ac5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        }
      },
      "source": [
        "print_scores(tempDf['ActualValue'], tempDf['PredictedClass'])\n",
        "print(\"ROC_AUC_Score: \", multiclass_roc_auc_score(tempDf['ActualValue'],tempDf['PredictedClass']))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score: \n",
            " 0.977756499963173\n",
            "Test-set confusion matrix:\n",
            " [[9111   46]\n",
            " [ 256 4164]]\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98      9157\n",
            "           1       0.99      0.94      0.97      4420\n",
            "\n",
            "    accuracy                           0.98     13577\n",
            "   macro avg       0.98      0.97      0.97     13577\n",
            "weighted avg       0.98      0.98      0.98     13577\n",
            "\n",
            "ROC_AUC_Score:  0.9685289843291758\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWYAAAD4CAYAAADfPUyRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzJKUGQOzJGXm/wGDqbnl7Bc/QAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmXx260B-8eB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJ28A2aN_iu_",
        "colab_type": "text"
      },
      "source": [
        "Showing Confusion Matrix for the First Group L12 and within that Assignment Groups clubbed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rC_Usem-7yz",
        "colab_type": "code",
        "outputId": "70502996-2649-4c47-b9a9-88ccff09e9c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 741
        }
      },
      "source": [
        "# tempDf_L12_AssignmentGroups\n",
        "print_scores(tempDf_L12_AssignmentGroups['ActualValue'], tempDf_L12_AssignmentGroups['PredictedClass'])\n",
        "print(\"ROC_AUC_Score: \", multiclass_roc_auc_score(tempDf_L12_AssignmentGroups['ActualValue'],tempDf_L12_AssignmentGroups['PredictedClass']))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score: \n",
            " 0.9060175054704596\n",
            "Test-set confusion matrix:\n",
            " [[2460   29   82   18    5   28    2    5]\n",
            " [   0 1128    0    0    0    0    0    0]\n",
            " [  57    4  758    4   20   81    0    6]\n",
            " [   0   92    0 1045   18    3    0    9]\n",
            " [   0    4    0    0  788    9    0   11]\n",
            " [   6    9   19    0   83  796    0    4]\n",
            " [   2   83    1    0    1    1  619   10]\n",
            " [   0  153    0    0    0    0    0  687]]\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.94      0.95      2629\n",
            "           1       0.75      1.00      0.86      1128\n",
            "           2       0.88      0.82      0.85       930\n",
            "           3       0.98      0.90      0.94      1167\n",
            "           4       0.86      0.97      0.91       812\n",
            "           5       0.87      0.87      0.87       917\n",
            "           6       1.00      0.86      0.93       717\n",
            "           7       0.94      0.82      0.87       840\n",
            "\n",
            "    accuracy                           0.91      9140\n",
            "   macro avg       0.91      0.90      0.90      9140\n",
            "weighted avg       0.92      0.91      0.91      9140\n",
            "\n",
            "ROC_AUC_Score:  0.9411440919011855\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWcAAAD4CAYAAAAw/yevAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wnTUmoG-7uS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8iqoBQm_sgB",
        "colab_type": "text"
      },
      "source": [
        "Showing Confusion Matrix for the Second Group L3 and within that Assignment Groups clubbed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8xt8rtl-7qK",
        "colab_type": "code",
        "outputId": "01dd688d-ea09-47d8-e198-03731b722453",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 707
        }
      },
      "source": [
        "print_scores(tempDf_L3_AssignmentGroups['ActualValue'], tempDf_L3_AssignmentGroups['PredictedClass'])\n",
        "print(\"ROC_AUC_Score: \", multiclass_roc_auc_score(tempDf_L3_AssignmentGroups['ActualValue'],tempDf_L3_AssignmentGroups['PredictedClass']))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score: \n",
            " 0.9725039441063782\n",
            "Test-set confusion matrix:\n",
            " [[662   0   0   0   4   0   0]\n",
            " [  0 778   0   0   0   0   0]\n",
            " [  0   0 629   0   0   0   0]\n",
            " [  0   0   0 614   0   0   0]\n",
            " [  0   0   0   0 580   0   0]\n",
            " [  0   2   1   0   6 556  76]\n",
            " [  0   0   9   2   7  15 496]]\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00       666\n",
            "           1       1.00      1.00      1.00       778\n",
            "           2       0.98      1.00      0.99       629\n",
            "           3       1.00      1.00      1.00       614\n",
            "           4       0.97      1.00      0.99       580\n",
            "           5       0.97      0.87      0.92       641\n",
            "           6       0.87      0.94      0.90       529\n",
            "\n",
            "    accuracy                           0.97      4437\n",
            "   macro avg       0.97      0.97      0.97      4437\n",
            "weighted avg       0.97      0.97      0.97      4437\n",
            "\n",
            "ROC_AUC_Score:  0.9833931895592495\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAD4CAYAAADSIzzWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/h9gaf/hOW7HkAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}